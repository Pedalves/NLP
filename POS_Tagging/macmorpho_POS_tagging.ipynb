{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gensim.models.word2vec as word2vec\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corpus = open('macmorpho-v1-dev.txt').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Por_PREP o_ART conteúdo_N de_PREP cada_PROADJ nova_ADJ lei_N que_PRO-KS-REL entra_V em_PREP vigor_N ,_, nota_V se_PROPESS um_ART aperfeiçoamento_N de_PREP a_ART malha_N jurídica_ADJ em_PREP essa_PROADJ área_N e_KC também_PDEN o_ART afunilamento_N de_PREP o_ART cerco_N fiscal_ADJ em_PREP torno_PREP de_PREP o_ART contribuinte_N ._.\\n',\n",
       "  'Agora_ADV ,_, nenhum_PROADJ cartório_N poderá_VAUX registrar_V quaisquer_PROADJ negócios_N ,_, operações_N ou_KC transações_N de_PREP imóveis_N rurais_ADJ sem_PREP o_ART comprovante_N de_PREP quitação_N de_PREP o_ART ITR_NPROP ._.\\n'],\n",
       " 2211)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_corpus[0:2], len(raw_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split words from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "unique_tokens = []\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    sentence_tokens = []\n",
    "    sentence_words = []\n",
    "    for word in sentence.split():\n",
    "        sentence_tokens.append(word.split('_')[1])\n",
    "        unique_tokens.append(word.split('_')[1])\n",
    "        sentence_words.append(word.split('_')[0])\n",
    "    tokens.append(sentence_tokens)\n",
    "    corpus.append(sentence_words)\n",
    "    \n",
    "unique_tokens=set(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '$',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '...',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'ADJ',\n",
       " 'ADV',\n",
       " 'ADV-KS',\n",
       " 'ADV-KS-REL',\n",
       " 'ART',\n",
       " 'CUR',\n",
       " 'IN',\n",
       " 'KC',\n",
       " 'KS',\n",
       " 'N',\n",
       " 'NPROP',\n",
       " 'NUM',\n",
       " 'PCP',\n",
       " 'PDEN',\n",
       " 'PREP',\n",
       " 'PRO-KS',\n",
       " 'PRO-KS-REL',\n",
       " 'PROADJ',\n",
       " 'PROPESS',\n",
       " 'PROSUB',\n",
       " 'V',\n",
       " 'VAUX',\n",
       " '`'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PREP', 'ART', 'N', 'PREP', 'PROADJ', 'ADJ', 'N', 'PRO-KS-REL', 'V', 'PREP', 'N', ',', 'V', 'PROPESS', 'ART', 'N', 'PREP', 'ART', 'N', 'ADJ', 'PREP', 'PROADJ', 'N', 'KC', 'PDEN', 'ART', 'N', 'PREP', 'ART', 'N', 'ADJ', 'PREP', 'PREP', 'PREP', 'ART', 'N', '.'], ['ADV', ',', 'PROADJ', 'N', 'VAUX', 'V', 'PROADJ', 'N', ',', 'N', 'KC', 'N', 'PREP', 'N', 'ADJ', 'PREP', 'ART', 'N', 'PREP', 'N', 'PREP', 'ART', 'NPROP', '.']] 2211\n"
     ]
    }
   ],
   "source": [
    "print(tokens[0:2], len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Por', 'o', 'conteúdo', 'de', 'cada', 'nova', 'lei', 'que', 'entra', 'em', 'vigor', ',', 'nota', 'se', 'um', 'aperfeiçoamento', 'de', 'a', 'malha', 'jurídica', 'em', 'essa', 'área', 'e', 'também', 'o', 'afunilamento', 'de', 'o', 'cerco', 'fiscal', 'em', 'torno', 'de', 'o', 'contribuinte', '.'], ['Agora', ',', 'nenhum', 'cartório', 'poderá', 'registrar', 'quaisquer', 'negócios', ',', 'operações', 'ou', 'transações', 'de', 'imóveis', 'rurais', 'sem', 'o', 'comprovante', 'de', 'quitação', 'de', 'o', 'ITR', '.']] 2211\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0:2], len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max sentence size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence = ''\n",
    "\n",
    "for sentence in corpus:\n",
    "    max_sentence = sentence if len(sentence) > len(max_sentence) else max_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leitura', 'Formando', 'Crianças', 'Leitoras', 'E', 'Produtoras', 'De', 'Textos', '(', '2', 'VOLS.', ')', ',', 'de', 'J.', 'Jolibert', 'Ler', 'E', 'Dizer', '-', 'Compreensão', 'E', 'Comunicação', 'Do', 'Texto', 'Escrito', ',', 'de', 'Elie', 'Bajard', 'Trabalho', 'O', 'Futuro', 'Do', 'Trabalho', ',', 'de', 'Marcia', 'de', 'Paula', 'Leite', 'Qualidade', 'De', 'Vida', 'NOTRABALHO', ',', 'de', 'Marcus', 'Vinicius', 'Carvalho', 'Rodrigues', 'Contos', 'Os', 'Gatos', 'Nus', 'Passeiam', 'Sobre', 'Os', 'Telhados', 'Sujos', ',', 'de', 'Josette', 'Lassance', 'Depois', 'Do', 'Século', ',', 'de', 'Tina', 'Schumacher', 'Outros', 'Piloto', 'Ianomâmi', ',', 'de', 'Tenn', 'Simioni', 'Condomínio', 'Do', 'Diabo', ',', 'de', 'Alba', 'Zaluar', 'Identidade', 'e', 'fluidez', 'em', 'a', 'sociedade', 'moderna', 'Editoria', ':', 'Mais', 'PáGINA', ':', '6-12', 'Identidade', 'e', 'fluidez', 'em', 'a', 'sociedade', 'moderna', 'Gilberto', 'Velho', 'aplica', 'o', 'conceito', 'de', 'metamorfose', 'a', 'a', 'análise', 'de', 'o', 'indivíduo', 'Paula', 'MONTERO', 'Especial', 'para', 'a', 'Folha', '\"', 'Projeto', 'e', 'Metamorfose', '\"', ',', 'o', 'mais', 'recente', 'livro', 'de', 'Gilberto', 'Velho', ',', 'aponta', ',', 'já', 'em', 'o', 'título', ',', 'para', 'um', 'de', 'os', 'mais', 'pungentes', 'temas', 'de', 'a', 'reflexão', 'contemporânea', ':', 'esse', 'impensado', 'de', 'a', 'ideologia', 'moderna', 'que', 'nos', 'habituamos', 'a', 'conceber', 'como', 'indivíduo', '.'] 171\n"
     ]
    }
   ],
   "source": [
    "print(max_sentence, len(max_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word_count = 1\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word2vec_model = word2vec.Word2Vec(\n",
    "    sg=1,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word2vec_model.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Word2Vec vocabulary length:\", word2vec_model.corpus_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word2vec_model.train(sentences=corpus, total_examples=word2vec_model.corpus_count, epochs=word2vec_model.iter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if not os.path.exists(\"trained\"):\n",
    "    os.makedirs(\"trained\")\n",
    "\n",
    "word2vec_model.save(os.path.join(\"trained\", \"word2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.Word2Vec.load(os.path.join(\"trained\", \"word2vec.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cabeça', 0.9169880151748657),\n",
       " ('mãe', 0.9164813756942749),\n",
       " ('filha', 0.9095824956893921),\n",
       " ('escola', 0.8843256235122681),\n",
       " ('mão', 0.8800747990608215),\n",
       " ('figura', 0.8661203384399414),\n",
       " ('porta', 0.8607738614082336),\n",
       " ('cama', 0.8491104245185852),\n",
       " ('frente', 0.8490560054779053),\n",
       " ('personalidade', 0.8461546897888184)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(\"mulher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get a feature vector corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_corpus = []\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
